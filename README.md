# 使用TensorFlow微调AlexNet

## 从caffemode中获取预训练权值
TensorFlow中没有预训练好的AlexNet模型，利用[caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow)工具可以将
在caffe上预训练好的AlexNet模型转成numpy的npy格式。该项目已经一年多没有人维护了，可能存在python、protobuf、tensorflow等版本不
兼容的问题。[这里](https://github.com/chuqidecha/caffe-tensorflow)是我改好的一个版本，使用Python3.6、protobuf3.6、tensorflow1.10版本。
从[Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)中可以下载在ImageNet上预训练好的AlexNet模型。
在[这里](https://pan.baidu.com/s/1b9N-z-5fYibKd8O2Vlg0Tg)下载已经转换好的参数文件(bvlc_alexnet.npy)。

## AlexNet模型结构与参数
AlexNet模型共有5个卷积层，3个全连接层，前两个卷积层和第五个卷积层后有池化层。
![image](./resources/alexnet.png)

1. 卷基层1
输入图像大小为227*227*3(BGR)；该层有96（每个GPU48个）个大小为11*11*3的卷积核，步长为4，不使用填充。
因此输出特征图大小为55*55*96（(227-11)/4+1=55）。参数个数为96*11*11*3+96=34944。
卷基层1之后紧跟一个LRN层，输出大小不变。
2. 池化层1
大小为3*3，步长为2。因此输出特征图大小为27*27*96（(55-3)/2+1=27）
3. 卷基层2
256个大小为5*5*48的卷积核（每个GPU各128个，分别作用于池化层1输出的前后48个通道），步长为1，使用填充。
因此输出特征图大小为2个27*27*128。参数个数为2*(128*5*5*48+128)=307456。卷基层2之后也会紧跟一个LRN层。
4. 池化层2
大小为3*3，步长为2。因此输出特征图大小为2个13*13*128（(27-3)/2+1=13）。
5. 卷基层3
有384个大小为3*3*256的卷积核（每个GPU各192个，作用于池化层2的所有输出），步长为1，使用填充。
因此输出特征图大小为2个13*13*192。参数个数为2*(192*3*3*256+192)=885120
6. 卷基层4
有384个大小为3*3*192的卷积核（仅作用于当前GPU），步长为1，使用填充。
因此输出特征图大小为2个13*13*192。参数个数为2*(192*3*3*192+192)=663936
7. 卷基层5
有256个大小为3*3*192的卷积核（仅作用于当前GPU），步长为1，使用填充。
因此输出特征图大小为2个13*13*128。参数个数为2*(128*3*3*192+128)=442624
8. 池化层5
大小为3*3，步长为2。因此输出特征图大小为2个6*6*128。
9. 全连接层1
节点数为4096，参数个数为6*6*128*2*4096+4096=37752832
10. 全连接层2
节点数为4096，参数个数为4096*4096+4096=16781312
11. 输出层
节点数为1000，参数个数为4096*1000+1000=4097000

